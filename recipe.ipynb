{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe for training JukeDrummer on a custom drum-covers dataset\n",
    "As we mostly reuse source code from [JukeDrummer](https://github.com/legoodmanner/jukedrummer), this fork adapts the python and shell scripts used.\n",
    "\n",
    "This notebook is mostly written as a report of the steps used, although most steps were actually run as scripts outside of the notebook.\n",
    "\n",
    "There was a lot of manual moving of files, therefore, if this notebook or any script glitches, please open an issue!\n",
    "\n",
    "In summary, these are the steps we will follow:\n",
    "\n",
    "0. Environment setup\n",
    "1. Baseline: Generate ~24s long accompanying drums using pre-trained checkpoint weights\n",
    "2. This work: Retrain JukeDrummer for a new dataset of drum covers:\n",
    "    - Generate a new dataset of paired drumless and drums audio files\n",
    "    - Preprocess this new dataset (segment, mel, beat extraction, language model tokens)\n",
    "    - Train the Jukedrummer models: VQ-VAEs and LanguageModel\n",
    "3. Demo: Run inference again, using the newly trained weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment \n",
    "We combine two public models:\n",
    "1. Demucs [ISMIR'21][ICASSP'23]: for creating a dataset of drumless and drums-only audio files from a personal collection of drum covers\n",
    "2. JukeDrummer [ISMIR'23]: for training a drum-accompaniment generation model. \n",
    "\n",
    "## JukeDrummer Fork\n",
    "The ISMIR'22 repo is here: https://github.com/legoodmanner/jukedrummer\n",
    "\n",
    "This repo had minor issues with package versions, and changes in some model keys and function arguments.\n",
    "\n",
    "A fork was used to make changes to the source repo:\n",
    "https://github.com/3x10e8/jukedrummer\n",
    "\n",
    "Refer to the [readme.md](./readme.md) file, now pointing to updated [requirements.txt](./requirements.txt)\n",
    "\n",
    "## Demucs Clone\n",
    "For creating a new dataset of audio files consisting of two steps: drums (target) and drumless (others), we will clone demucs:\n",
    "\n",
    "https://github.com/adefossez/demucs\n",
    "\n",
    "I went with the option of creating a conda environment using the provided [environment-cuda.yml](https://github.com/adefossez/demucs/blob/main/environment-cuda.yml).\n",
    "\n",
    "```\n",
    "conda env update -f environment-cuda.yml\n",
    "conda activate demucs\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "`pip` threw warnings about making an editable install.\n",
    "\n",
    "Furthermore, testing demucs for trying to convert the included [test.mp3](https://github.com/adefossez/demucs/blob/main/test.mp3):\n",
    "```\n",
    "torch.from_numpy(wav) RuntimeError: Numpy is not available\n",
    "```\n",
    "This seemed to originate from using a newer numpy version, as [environment-cuda.yml](https://github.com/adefossez/demucs/blob/main/environment-cuda.yml) did not specify a numpy version.\n",
    "\n",
    "Fixable by downgrading:\n",
    "\n",
    "`pip install --upgrade numpy==1.24.1` resolved this issue."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drum Covers Dataset\n",
    "\n",
    "I ran demucs on a dataset of drum covers previously recorded as WAV files.\n",
    "\n",
    "Parameter | Value\n",
    ":-- | :--\n",
    "Number of WAV (total drum covers) | 347\n",
    "Number of drummers | 1*\n",
    "Total duration** | 18 hours, 44 minutes, 59 seconds\n",
    "Drum covers were mostly performed for this playlist | [YouTube](https://www.youtube.com/playlist?list=PLVeAUqPtEmT4D5u7DbwJRtJ0nu_00Pb53)\n",
    "\n",
    "*occasionally more if the backing track also had drums (not excluded), but this should be only a small subset\n",
    "\n",
    "**extracted using: [get_wav_duration.py](https://gist.github.com/Wazzabeee/5dc05b11b8529457cde7b3fea0c0a45e)\n",
    "\n",
    "Some notes on this drum cover dataset:\n",
    "1. Recordings were made on a Roland TD-25: an electronic drumkit that allows playing along to music (as a backing track).\n",
    "2. Each drum cover was saved as one WAV file, combining the drum cover and the backing music (often drumless) into one file.\n",
    "    - Some files probably had original drums in the backing tracks, resulting in two drum tracks being overlaid in the covers. These files were not identified nor excluded.\n",
    "    - Similarly, some files would have consisted of just the drums, without any backing tracks. These were also not excluded.\n",
    "3. Some (if not all) songs were covered multiple times. Repeated covers could get split between train and validation sets (this was not controlled for).\n",
    "3. Not all drum covers used the same drum sounds, nor would the volumes have matched across recordings.\n",
    "4. The drum covers were not perfect -- there would be timing errors!\n",
    "5. The trained model aims to generate drum tracks based on how I play the drums, it is not intended to generate music from the source playlist.\n",
    "\n",
    "### Running demucs\n",
    "WAVs were copied into one directory, and then demucs was run using:\n",
    "\n",
    "`demucs -o . --filename \"{stem}/{track}.{ext}\" -j 20 --two-stems drums *.WAV`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JukeDrummer: Inference with pre-trained weights\n",
    "\n",
    "First, we copy over a drumless WAV, and truncate it to 23.78 seconds (seems to work for the network layer size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python input_drumless/truncate_to_24s/sounds/truncate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference.py --exp_idx 1 --cuda 0 --ckpt_dir ckpt/ --input_dir input_drumless --output_dir output_with_drums/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash script/preprocessing.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training JukeDrummer on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train_vqvae.py --vq_idx 1 --data_type target --cuda 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train_vqvae.py --vq_idx 1 --data_type others --cuda 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 token_extract.py --cuda 0 --vq_idx 1 --data_type target --ckpt_dir ckpt_3x10e8/ --mel_dir data/mel --output_dir data/token\n",
    "!python3 token_extract.py --cuda 0 --vq_idx 1 --data_type others --ckpt_dir ckpt_3x10e8/ --mel_dir data/mel --output_dir data/token\n",
    "!python3 train_lm.py --cuda 0 --exp_idx 1 #--wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckpt in [\n",
    "    'ckpt/',                # pretrained\n",
    "    'ckpt_lm_tr86_epo300/', # pretrained vq, train LM on smaller train set\n",
    "    'ckpt_lm_tr124_epo40/', # pretrained vq, train LM on larger train set\n",
    "    'ckpt_lm_tr124_epo60/', # pretrained vq, train LM on larger train set for more epochs\n",
    "    'ckpt_vq_tr62_epo69/',  # train vq, reuse trained LM from last run\n",
    "    'ckpt_vq,lm_tr124_epo350/', # final model\n",
    "]:\n",
    "    !python inference.py --exp_idx 1 --cuda 0 --ckpt_dir {ckpt} --input_dir input_drumless --output_dir output_with_drums/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "Training only LM weights for 60 epochs, using the new dataset, embedded using pre-trained (ISMIR'23) VD-VQE weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash script/train.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
